{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##**Part** III: Comparative Analysis"
      ],
      "metadata": {
        "id": "MqRKE4IWhRaq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
      ],
      "metadata": {
        "id": "m-BRikA4hEZF"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load data\n",
        "df = pd.read_csv(\"/content/spam.csv\", encoding=\"latin-1\")[['v1', 'v2']]\n",
        "df.columns = ['label', 'text']\n",
        "y = df['label'].map({'ham': 0, 'spam': 1}).values\n",
        "X_raw = df['text'].values"
      ],
      "metadata": {
        "id": "JVmkMM9vhD1n"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Naive Bayes Implementation\n",
        "class NaiveBayes:\n",
        "    def __init__(self, alpha=1.0):\n",
        "        self.alpha = alpha\n",
        "        self.class_priors = {}\n",
        "        self.word_likelihoods = {}\n",
        "        self.vocab_size = 0\n",
        "        self.classes = []\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.classes = np.unique(y)\n",
        "        n_docs = len(y)\n",
        "        self.class_priors = {c: np.sum(y == c) / n_docs for c in self.classes}\n",
        "        word_counts = {c: np.zeros(X.shape[1]) for c in self.classes}\n",
        "        class_word_totals = {c: 0 for c in self.classes}\n",
        "        for c in self.classes:\n",
        "            X_c = X[y == c]\n",
        "            word_counts[c] = np.sum(X_c, axis=0)\n",
        "            class_word_totals[c] = np.sum(word_counts[c])\n",
        "        self.vocab_size = X.shape[1]\n",
        "        self.word_likelihoods = {\n",
        "            c: (word_counts[c] + self.alpha) /\n",
        "               (class_word_totals[c] + self.alpha * self.vocab_size)\n",
        "            for c in self.classes\n",
        "        }\n",
        "\n",
        "    def predict(self, X):\n",
        "        predictions = []\n",
        "        for x in X:\n",
        "            class_scores = {}\n",
        "            for c in self.classes:\n",
        "                score = np.log(self.class_priors[c])\n",
        "                score += np.sum(x * np.log(self.word_likelihoods[c]))\n",
        "                class_scores[c] = score\n",
        "            predictions.append(max(class_scores, key=class_scores.get))\n",
        "        return np.array(predictions)"
      ],
      "metadata": {
        "id": "1k2PavcVgKi1"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Logistic Regression\n",
        "class LogisticRegressionScratch:\n",
        "    def __init__(self, learning_rate=0.01, epochs=500, lambda_=0.0):\n",
        "        self.lr = learning_rate\n",
        "        self.epochs = epochs\n",
        "        self.lambda_ = lambda_\n",
        "        self.weights = None\n",
        "        self.bias = 0\n",
        "\n",
        "    def _sigmoid(self, z):\n",
        "        return 1 / (1 + np.exp(-z))\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        m, n = X.shape\n",
        "        self.weights = np.zeros(n)\n",
        "        self.bias = 0\n",
        "        for _ in range(self.epochs):\n",
        "            z = np.dot(X, self.weights) + self.bias\n",
        "            h = self._sigmoid(z)\n",
        "            dw = (1/m) * np.dot(X.T, (h - y)) + (self.lambda_ / m) * self.weights\n",
        "            db = (1/m) * np.sum(h - y)\n",
        "            self.weights -= self.lr * dw\n",
        "            self.bias -= self.lr * db\n",
        "\n",
        "    def predict(self, X):\n",
        "        z = np.dot(X, self.weights) + self.bias\n",
        "        return (self._sigmoid(z) >= 0.5).astype(int)"
      ],
      "metadata": {
        "id": "_jT39TS-hLwd"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# to train & evaluate\n",
        "def evaluate_model(model, X_train, X_test, y_train, y_test, name):\n",
        "    model.fit(X_train, y_train)\n",
        "    preds = model.predict(X_test)\n",
        "    return {\n",
        "        \"Model\": name,\n",
        "        \"Accuracy\": accuracy_score(y_test, preds),\n",
        "        \"Precision\": precision_score(y_test, preds),\n",
        "        \"Recall\": recall_score(y_test, preds),\n",
        "        \"F1\": f1_score(y_test, preds)\n",
        "    }"
      ],
      "metadata": {
        "id": "-6uUwL7OhPe2"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "#native bayes using both\n",
        "for vec_name, vectorizer in [(\"Count\", CountVectorizer()), (\"TF-IDF\", TfidfVectorizer())]:\n",
        "    X_vec = vectorizer.fit_transform(X_raw).toarray()\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_vec, y, test_size=0.2, random_state=42, stratify=y)\n",
        "    nb = NaiveBayes(alpha=1.0)\n",
        "    res = evaluate_model(nb, X_train, X_test, y_train, y_test, f\"Naive Bayes ({vec_name})\")\n",
        "    results.append(res)\n",
        "#logistic using both\n",
        "scaler = StandardScaler()\n",
        "for vec_name, vectorizer in [(\"Count\", CountVectorizer()), (\"TF-IDF\", TfidfVectorizer())]:\n",
        "    X_vec = vectorizer.fit_transform(X_raw).toarray()\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_vec, y, test_size=0.2, random_state=42, stratify=y)\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_test = scaler.transform(X_test)\n",
        "    log_reg = LogisticRegressionScratch(learning_rate=0.01, epochs=1000, lambda_=0.1)\n",
        "    res = evaluate_model(log_reg, X_train, X_test, y_train, y_test, f\"Logistic Regression ({vec_name})\")\n",
        "    results.append(res)"
      ],
      "metadata": {
        "id": "S4-SU6Z1gY4D"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_results = pd.DataFrame(results)\n",
        "print(df_results.to_string(index=False))"
      ],
      "metadata": {
        "id": "C0E5d3lngSHb",
        "outputId": "7781c5b2-f150-4f36-fec9-ae1711f5b596",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                       Model  Accuracy  Precision   Recall       F1\n",
            "         Naive Bayes (Count)  0.981166   0.915584 0.946309 0.930693\n",
            "        Naive Bayes (TF-IDF)  0.961435   1.000000 0.711409 0.831373\n",
            " Logistic Regression (Count)  0.990135   0.985915 0.939597 0.962199\n",
            "Logistic Regression (TF-IDF)  0.983857   0.951724 0.926174 0.938776\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colab",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}